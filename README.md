# Link do Projeto:
https://colab.research.google.com/drive/1G1bYMqgHySTBupL3LFSdbrB8uXosiKhp?usp=sharing

# SegmentaÃ§Ã£o de Vasos Retinianos com U-Net e U-Net++

Este projeto utiliza redes neurais convolucionais U-Net e U-Net++ para segmentaÃ§Ã£o de vasos sanguÃ­neos em imagens da retina a partir do **DRIVE Dataset**. 

O objetivo Ã© identificar estruturas importantes â€“ como vasos sanguÃ­neos â€“ auxiliando diagnÃ³sticos oftalmolÃ³gicos. 

VisualizaÃ§Ã£o das iamgens:
<img width="1398" height="674" alt="image" src="https://github.com/user-attachments/assets/dba4b11d-1588-4b60-a09d-1fc73b71aaaa" />

Esse projeto Ã© composto por 40 imagens, 20 de teste e 20 de treino, o que Ã© pouco para um bom treinamento, por isso foi necessÃ¡rio gerar novos dados a partir das patches, as patchs foram essenciais para esse projeto, uma vez que as imagens originaris tinham proporÃ§Ãµes de 584x565, porem o colab tradicional limita para no mÃ¡ximo 128x128, nessa proporÃ§Ã£o parte da qualidade das imagens se perdiam, o que resultava em um pÃ©ssimo resultado.

## ğŸ“ Estrutura do Projeto

```
ğŸ“‚ DRIVE
 â”œâ”€â”€ training
 â”‚   â”œâ”€â”€ images           # Imagens originais em .tif
 â”‚   â”œâ”€â”€ 1st_manual       # MÃ¡scaras manuais (rÃ³tulos) em .gif
 â”‚   â””â”€â”€ mask             # MÃ¡scaras de campo de visÃ£o (FOV)

 â”œâ”€â”€ test
 â”‚   â”œâ”€â”€ images          
 â”‚   â””â”€â”€ mask          
```

## ğŸš€ Tecnologias Utilizadas

- Python
- TensorFlow / Keras
- NumPy
- OpenCV
- Matplotlib
- scikit-learn
- Google Colab

## âš™ï¸ PrÃ©-processamento

- NormalizaÃ§Ã£o das imagens (valores entre 0 e 1).
- BinarizaÃ§Ã£o das mÃ¡scaras: A binarizaÃ§Ã£o Ã© essencial para:
    Garantir que a mÃ¡scara sÃ³ indique presenÃ§a (1.0) ou ausÃªncia (0.0) do objeto/estrutura de interesse.
    Facilitar o treino com modelos de segmentaÃ§Ã£o binÃ¡ria, como U-Net ou SegNet.
    Evitar inconsistÃªncias nos dados vindos de arquivos de imagem.
  
- ExtraÃ§Ã£o de patches (128x128 com stride 64): O cÃ³digo divide imagens grandes em pequenos blocos (patches). SÃ³ usa os patches onde hÃ¡ conteÃºdo relevante (mÃ¡scara com valores > 0), isso reduz a quantidade de dados desnecessÃ¡rios e melhora o desempenho do modelo de segmentaÃ§Ã£o.
  
- Aumento de dados com `ImageDataGenerator`.

## ğŸ§  Modelos Utilizados

### ğŸ”· U-Net

**U-Net** Ã© uma arquitetura de rede neural voltada para segmentaÃ§Ã£o semÃ¢ntica pixel a pixel. Ela Ã© composta por:

- **Encoder (contrator):** extrai caracterÃ­sticas com camadas de convoluÃ§Ã£o, ReLU e MaxPooling.
- **Decoder (expansor):** reconstrÃ³i a imagem com camadas de transposed convolution.
- **Skip connections:** liga diretamente camadas correspondentes do encoder ao decoder, preservando detalhes espaciais.

> ğŸ” Ãštil para tarefas com imagens mÃ©dicas e dados limitados, oferece bons resultados com custo computacional moderado.

---

### ğŸ”¶ U-Net++

**U-Net++** Ã© uma extensÃ£o da U-Net, com melhorias significativas para segmentaÃ§Ãµes mais complexas.

#### Principais DiferenÃ§as:

- **ConexÃµes aninhadas e densas:** conecta mÃºltiplos nÃ­veis intermediÃ¡rios entre encoder e decoder.
- **Maior profundidade:** incorpora mais camadas para melhorar a extraÃ§Ã£o semÃ¢ntica.
- **Deep supervision (opcional):** supervisiona saÃ­das intermediÃ¡rias durante o treinamento.

> ğŸš€ Ideal para quando se busca maior precisÃ£o, mesmo com maior custo computacional.

---

## ğŸ“Š ComparaÃ§Ã£o

| CaracterÃ­stica             | U-Net                         | U-Net++                       |
|---------------------------|-------------------------------|-------------------------------|
| Estrutura                 | Encoder-decoder               | Encoder-decoder com conexÃµes densas |
| Skip Connections          | Diretas                       | Aninhadas e profundas         |
| Aprendizado semÃ¢ntico     | RazoÃ¡vel                      | Mais refinado                 |
| GeneralizaÃ§Ã£o             | Boa                           | Melhor em dados complexos     |
| Custo computacional       | Menor                         | Maior                         |
| Suporte a deep supervision| NÃ£o                           | Sim (opcional)                |

---

## ğŸ“ˆ Treinamento

- Otimizador: `Adam`
- FunÃ§Ã£o de perda: `binary_crossentropy`
- MÃ©tricas: `accuracy`, alÃ©m de mÃ©tricas personalizadas com base em segmentaÃ§Ã£o binÃ¡ria
- EarlyStopping e ModelCheckpoint utilizados para evitar overfitting.

## ğŸ“Š MÃ©tricas Avaliadas

As mÃ©tricas utilizadas para comparar os modelos foram:

- **Loss**
- **AcurÃ¡cia**
- **Sensibilidade (Recall)**
- **Especificidade**
- **AUC-ROC**

As mÃ¡scaras preditas passaram por pÃ³s-processamento usando operaÃ§Ãµes morfolÃ³gicas (open/close) para remoÃ§Ã£o de ruÃ­dos.

## ğŸ” VisualizaÃ§Ãµes

O projeto inclui:

- VisualizaÃ§Ã£o de imagens e mÃ¡scaras originais
- VisualizaÃ§Ã£o de imagens aumentadas
- ComparaÃ§Ã£o lado a lado entre as prediÃ§Ãµes da U-Net e da U-Net++
- ExibiÃ§Ã£o de prediÃ§Ãµes binarizadas com limiar (threshold ajustÃ¡vel)

## ğŸ§ª AvaliaÃ§Ã£o e ComparaÃ§Ã£o

Os modelos foram avaliados utilizando os patches de validaÃ§Ã£o extraÃ­dos do conjunto original.

```python
comparar_modelos(model_unet, model, val_img_patches, val_mask_patches, threshold=0.1)
```

Este mÃ©todo apresenta os seguintes resultados:

- **MÃ©dia da loss**
- **MÃ©dia da acurÃ¡cia**
- **Sensibilidade mÃ©dia**
- **Especificidade mÃ©dia**
- **AUC-ROC mÃ©dia**

---

## ğŸ“¦ Resultados

## Unet++:

<img width="1182" height="379" alt="image" src="https://github.com/user-attachments/assets/c03a1a96-b436-4cd6-9cab-aa7bdb4424db" />

<img width="1167" height="393" alt="image" src="https://github.com/user-attachments/assets/14c8ad4d-3ea1-48fa-82c0-3b4800a86fb8" />

## Unet:
<img width="1174" height="425" alt="image" src="https://github.com/user-attachments/assets/3d5bbe00-5c2c-4999-bda2-3164ab2f1896" />

<img width="1180" height="400" alt="image" src="https://github.com/user-attachments/assets/e6dbec7b-2078-4e3d-8f5d-e95ceb0c35c5" />


## ğŸ“Š MÃ©tricas de AvaliaÃ§Ã£o

### ğŸ”¹ U-Net
- **Loss mÃ©dia:** 0.0973  
- **AcurÃ¡cia mÃ©dia:** 0.9622  
- **Sensibilidade mÃ©dia:** 0.9054  
- **Especificidade mÃ©dia:** 0.9185  
- **AUC-ROC mÃ©dia:** 0.9761  

### ğŸ”¸ U-Net++
- **Loss mÃ©dia:** 0.0867  
- **AcurÃ¡cia mÃ©dia:** 0.9660  
- **Sensibilidade mÃ©dia:** 0.9291  
- **Especificidade mÃ©dia:** 0.9263  
- **AUC-ROC mÃ©dia:** 0.9840  

U-Net++ teve melhor desempenho em todas as mÃ©tricas, indicando que:

Ela erra menos (menor loss),

Classifica com maior precisÃ£o geral (acurÃ¡cia),

Tem maior sensibilidade (detecta melhor os positivos),

Maior especificidade (detecta melhor os negativos),

E melhor separaÃ§Ã£o entre classes (AUC-ROC).

Portanto, U-Net++ Ã© a melhor escolha com base nesses resultados.

---

## ğŸ“Œ ObservaÃ§Ã£o

O `threshold=0.1` foi utilizado para binarizar as prediÃ§Ãµes. Isso ajuda a captar vasos mais finos, mas deve ser ajustado conforme necessÃ¡rio. Um valor muito baixo pode aumentar o nÃºmero de falsos positivos.

---

## ğŸ“ ReferÃªncia

- Dataset: [DRIVE - Digital Retinal Images for Vessel Extraction](https://www.kaggle.com/datasets/andrewmvd/drive-digital-retinal-images-for-vessel-extraction?resource=download)
- Artigos:
  - U-Net: *Ronneberger et al., 2015*
  - U-Net++: *Zhou et al., 2018*


## ğŸ§‘â€ğŸ’» Autor

- **Phaola Paraguai Da PaixÃ£o Lustosa**
- Email: <paxaophaola@gmail.com>

---
